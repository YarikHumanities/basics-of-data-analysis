{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.51596</td>\n",
       "      <td>12.79</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.62</td>\n",
       "      <td>72.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.51743</td>\n",
       "      <td>13.30</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.14</td>\n",
       "      <td>73.09</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.51756</td>\n",
       "      <td>13.15</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.05</td>\n",
       "      <td>73.24</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.51918</td>\n",
       "      <td>14.04</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.37</td>\n",
       "      <td>72.08</td>\n",
       "      <td>0.56</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.51755</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba    Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.00     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.00     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.00     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.00     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.00     1\n",
       "5  1.51596  12.79  3.61  1.62  72.97  0.64  8.07  0.0  0.26     1\n",
       "6  1.51743  13.30  3.60  1.14  73.09  0.58  8.17  0.0  0.00     1\n",
       "7  1.51756  13.15  3.61  1.05  73.24  0.57  8.24  0.0  0.00     1\n",
       "8  1.51918  14.04  3.58  1.37  72.08  0.56  8.30  0.0  0.00     1\n",
       "9  1.51755  13.00  3.60  1.36  72.99  0.57  8.40  0.0  0.11     1"
      ]
     },
     "execution_count": 1616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('glass.csv')\n",
    "dataset.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RI      float64\n",
       "Na      float64\n",
       "Mg      float64\n",
       "Al      float64\n",
       "Si      float64\n",
       "K       float64\n",
       "Ca      float64\n",
       "Ba      float64\n",
       "Fe      float64\n",
       "Type      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 1617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of           RI     Na    Mg    Al     Si     K    Ca    Ba   Fe  Type\n",
       "0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0     1\n",
       "1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0     1\n",
       "2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0     1\n",
       "3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0     1\n",
       "4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0     1\n",
       "..       ...    ...   ...   ...    ...   ...   ...   ...  ...   ...\n",
       "209  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0     7\n",
       "210  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0     7\n",
       "211  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0     7\n",
       "212  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0     7\n",
       "213  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0     7\n",
       "\n",
       "[214 rows x 10 columns]>"
      ]
     },
     "execution_count": 1618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.518365</td>\n",
       "      <td>13.407850</td>\n",
       "      <td>2.684533</td>\n",
       "      <td>1.444907</td>\n",
       "      <td>72.650935</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>8.956963</td>\n",
       "      <td>0.175047</td>\n",
       "      <td>0.057009</td>\n",
       "      <td>2.780374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.816604</td>\n",
       "      <td>1.442408</td>\n",
       "      <td>0.499270</td>\n",
       "      <td>0.774546</td>\n",
       "      <td>0.652192</td>\n",
       "      <td>1.423153</td>\n",
       "      <td>0.497219</td>\n",
       "      <td>0.097439</td>\n",
       "      <td>2.103739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.511150</td>\n",
       "      <td>10.730000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>69.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.430000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.516522</td>\n",
       "      <td>12.907500</td>\n",
       "      <td>2.115000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>72.280000</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>8.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.517680</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>72.790000</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.519157</td>\n",
       "      <td>13.825000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>73.087500</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>9.172500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.533930</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>4.490000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>75.410000</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>16.190000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RI          Na          Mg          Al          Si           K  \\\n",
       "count  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000   \n",
       "mean     1.518365   13.407850    2.684533    1.444907   72.650935    0.497056   \n",
       "std      0.003037    0.816604    1.442408    0.499270    0.774546    0.652192   \n",
       "min      1.511150   10.730000    0.000000    0.290000   69.810000    0.000000   \n",
       "25%      1.516522   12.907500    2.115000    1.190000   72.280000    0.122500   \n",
       "50%      1.517680   13.300000    3.480000    1.360000   72.790000    0.555000   \n",
       "75%      1.519157   13.825000    3.600000    1.630000   73.087500    0.610000   \n",
       "max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   \n",
       "\n",
       "               Ca          Ba          Fe        Type  \n",
       "count  214.000000  214.000000  214.000000  214.000000  \n",
       "mean     8.956963    0.175047    0.057009    2.780374  \n",
       "std      1.423153    0.497219    0.097439    2.103739  \n",
       "min      5.430000    0.000000    0.000000    1.000000  \n",
       "25%      8.240000    0.000000    0.000000    1.000000  \n",
       "50%      8.600000    0.000000    0.000000    2.000000  \n",
       "75%      9.172500    0.000000    0.100000    3.000000  \n",
       "max     16.190000    3.150000    0.510000    7.000000  "
      ]
     },
     "execution_count": 1619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RI      178\n",
       "Na      142\n",
       "Mg       94\n",
       "Al      118\n",
       "Si      133\n",
       "K        65\n",
       "Ca      143\n",
       "Ba       34\n",
       "Fe       32\n",
       "Type      6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1621,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# LabelEncoder().fit_transform(dataset.Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1622,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Is_Type_7'] = np.where(dataset['Type'] == 7, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "      <th>Is_Type_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.51596</td>\n",
       "      <td>12.79</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.62</td>\n",
       "      <td>72.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.51743</td>\n",
       "      <td>13.30</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.14</td>\n",
       "      <td>73.09</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.51756</td>\n",
       "      <td>13.15</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.05</td>\n",
       "      <td>73.24</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.51918</td>\n",
       "      <td>14.04</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.37</td>\n",
       "      <td>72.08</td>\n",
       "      <td>0.56</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.51755</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba    Fe  Type  Is_Type_7\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.00     1          0\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.00     1          0\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.00     1          0\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.00     1          0\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.00     1          0\n",
       "5  1.51596  12.79  3.61  1.62  72.97  0.64  8.07  0.0  0.26     1          0\n",
       "6  1.51743  13.30  3.60  1.14  73.09  0.58  8.17  0.0  0.00     1          0\n",
       "7  1.51756  13.15  3.61  1.05  73.24  0.57  8.24  0.0  0.00     1          0\n",
       "8  1.51918  14.04  3.58  1.37  72.08  0.56  8.30  0.0  0.00     1          0\n",
       "9  1.51755  13.00  3.60  1.36  72.99  0.57  8.40  0.0  0.11     1          0"
      ]
     },
     "execution_count": 1623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.864486\n",
       "1    0.135514\n",
       "Name: Is_Type_7, dtype: float64"
      ]
     },
     "execution_count": 1624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[dataset['Is_Type_7']==1].count()\n",
    "dataset.Is_Type_7.value_counts(normalize=True)\n",
    "\n",
    "# 29 Rows with Type 7. All Rows = 214\n",
    "# So we should make Test Values And Train Values so that them will have equal percentage of Glasses With Type 7\n",
    "# It'a about 14% per each Value Group - Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1625,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = dataset.pop('Is_Type_7')\n",
    "X = dataset.drop(columns='Type')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=2023)\n",
    "\n",
    "# WITHOUT STRATIFY\n",
    "\n",
    "# stratify — если задан, то метод разбивает на трейн и тест так, чтобы отношение данных разных классов в подвыборках было одинаковым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 9)\n",
      "(214,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X))\n",
    "print(np.shape(Y))\n",
    "\n",
    "print(type(X))\n",
    "print(type(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1627,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "glass_type_logistic_regression = Pipeline([('scale', StandardScaler()), ('logistic_regression', LogisticRegression(class_weight='balanced', random_state=0))])\n",
    "# glass_type_logistic_regression = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-84 {color: black;background-color: white;}#sk-container-id-84 pre{padding: 0;}#sk-container-id-84 div.sk-toggleable {background-color: white;}#sk-container-id-84 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-84 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-84 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-84 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-84 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-84 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-84 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-84 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-84 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-84 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-84 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-84 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-84 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-84 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-84 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-84 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-84 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-84 div.sk-item {position: relative;z-index: 1;}#sk-container-id-84 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-84 div.sk-item::before, #sk-container-id-84 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-84 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-84 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-84 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-84 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-84 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-84 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-84 div.sk-label-container {text-align: center;}#sk-container-id-84 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-84 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-84\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n",
       "                (&#x27;logistic_regression&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-262\" type=\"checkbox\" ><label for=\"sk-estimator-id-262\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n",
       "                (&#x27;logistic_regression&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-263\" type=\"checkbox\" ><label for=\"sk-estimator-id-263\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-264\" type=\"checkbox\" ><label for=\"sk-estimator-id-264\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=0)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()),\n",
       "                ('logistic_regression',\n",
       "                 LogisticRegression(class_weight='balanced', random_state=0))])"
      ]
     },
     "execution_count": 1628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass_type_logistic_regression.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0])"
      ]
     },
     "execution_count": 1629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_prediction = glass_type_logistic_regression.predict(X_test)\n",
    "type_prediction[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47  2]\n",
      " [ 0  5]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1630,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "mat = confusion_matrix(Y_test, type_prediction)\n",
    "print(mat)\n",
    "sns.heatmap(mat, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629629629629629"
      ]
     },
     "execution_count": 1631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass_type_logistic_regression.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03703703703703709"
      ]
     },
     "execution_count": 1632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "zero_one_loss(Y_test, type_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        49\n",
      "           1       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.96        54\n",
      "   macro avg       0.86      0.98      0.91        54\n",
      "weighted avg       0.97      0.96      0.97        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_test, type_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1634,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x26574bfffd0>"
      ]
     },
     "execution_count": 1634,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "# Это соотношение между ложными срабатываниями (количество прогнозов, ошибочно отнесённых в положительные), и всеми доступными\n",
    "\n",
    "plot_roc_curve(glass_type_logistic_regression, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1635,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "pipeline = Pipeline([('scale', MinMaxScaler()),('lr', LogisticRegression(class_weight='balanced',random_state=0))])\n",
    "search_space = {'lr__C': np.logspace(-1, 1, num=10),'lr__fit_intercept': [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1636,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid = GridSearchCV(pipeline, search_space, scoring='f1_macro', cv=5).fit(X_train, Y_train)\n",
    "\n",
    "# RepeatedStratifiedKFold(random_state=0) - Or You can try this in CV\n",
    "\n",
    "# scoring = Strategy to evaluate the performance of the cross-validated model on the test set\n",
    "# cv = Determines the cross-validation splitting strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1637,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'lr__C': 3.593813663804626, 'lr__fit_intercept': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.593813663804626"
      ]
     },
     "execution_count": 1637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best params: \", lr_grid.best_params_)\n",
    "lr_grid.best_params_['lr__C']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg2=LogisticRegression(C=3.5, fit_intercept=True)\n",
    "logreg2.fit(X_train, Y_train)\n",
    "print(\"Score: \", logreg2.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1639,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "type_prediction_2 = logreg2.predict(X_test)\n",
    "print(classification_report(Y_test, type_prediction_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Model: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        49\n",
      "           1       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.96        54\n",
      "   macro avg       0.86      0.98      0.91        54\n",
      "weighted avg       0.97      0.96      0.97        54\n",
      "\n",
      "Third Model: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        49\n",
      "           1       0.56      1.00      0.71         5\n",
      "\n",
      "    accuracy                           0.93        54\n",
      "   macro avg       0.78      0.96      0.84        54\n",
      "weighted avg       0.96      0.93      0.93        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures # додає нові ознаки взаємодії\n",
    "\n",
    "def generate_degrees(source_data: list, degree: int):\n",
    "       return np.array([source_data**n for n in range(1, degree + 1)]).T\n",
    "\n",
    "\n",
    "pipeline = Pipeline([('poly', PolynomialFeatures(degree=2)),\n",
    "                    ('scale', MinMaxScaler()),\n",
    "                    ('lr', LogisticRegression(class_weight='balanced', random_state=0))]).fit(X_train, Y_train)\n",
    "\n",
    "type_prediction_3 = pipeline.predict(X_test)\n",
    "print(\"First Model: \\n\", classification_report(Y_test, type_prediction))\n",
    "print(\"Third Model: \\n\", classification_report(Y_test, type_prediction_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1641,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bokeh.plotting import figure, show, output_file\n",
    "\n",
    "# p=figure(title=\"Actual vs Predicted\", width=450, height=300)\n",
    "# p.title.align = 'center'\n",
    "# p.circle(df.Exp, df.Salary)\n",
    "# p.line(df.Exp, df.Salary, legend_label='Actual Salary', line_width=3, line_alpha=0.4)\n",
    "# p.circle(df.Exp, yp, color=\"red\")\n",
    "# p.line(df.Exp,yp, color=\"red\",legend_label='Predicted Salary', line_width=3, line_alpha=0.4)\n",
    "# p.xaxis.axis_label = 'Experience'\n",
    "# p.yaxis.axis_label = 'Salary'\n",
    "# show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000000e+00, 1.511310e+00, 1.369000e+01, ..., 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00],\n",
       "       [1.000000e+00, 1.516650e+00, 1.314000e+01, ..., 0.000000e+00,\n",
       "        0.000000e+00, 1.419857e-04],\n",
       "       [1.000000e+00, 1.518410e+00, 1.302000e+01, ..., 0.000000e+00,\n",
       "        0.000000e+00, 7.593750e-05],\n",
       "       ...,\n",
       "       [1.000000e+00, 1.515310e+00, 1.438000e+01, ..., 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00],\n",
       "       [1.000000e+00, 1.517640e+00, 1.298000e+01, ..., 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00],\n",
       "       [1.000000e+00, 1.516450e+00, 1.340000e+01, ..., 0.000000e+00,\n",
       "        0.000000e+00, 1.000000e-05]])"
      ]
     },
     "execution_count": 1642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = PolynomialFeatures(degree=5).fit_transform(X_train)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-85 {color: black;background-color: white;}#sk-container-id-85 pre{padding: 0;}#sk-container-id-85 div.sk-toggleable {background-color: white;}#sk-container-id-85 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-85 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-85 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-85 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-85 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-85 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-85 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-85 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-85 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-85 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-85 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-85 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-85 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-85 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-85 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-85 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-85 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-85 div.sk-item {position: relative;z-index: 1;}#sk-container-id-85 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-85 div.sk-item::before, #sk-container-id-85 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-85 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-85 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-85 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-85 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-85 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-85 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-85 div.sk-label-container {text-align: center;}#sk-container-id-85 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-85 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-85\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;feature_selection&#x27;, VarianceThreshold(threshold=0.01)),\n",
       "                (&#x27;scale&#x27;, StandardScaler()),\n",
       "                (&#x27;lr&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-265\" type=\"checkbox\" ><label for=\"sk-estimator-id-265\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;feature_selection&#x27;, VarianceThreshold(threshold=0.01)),\n",
       "                (&#x27;scale&#x27;, StandardScaler()),\n",
       "                (&#x27;lr&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-266\" type=\"checkbox\" ><label for=\"sk-estimator-id-266\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold(threshold=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-267\" type=\"checkbox\" ><label for=\"sk-estimator-id-267\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-268\" type=\"checkbox\" ><label for=\"sk-estimator-id-268\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=0)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('feature_selection', VarianceThreshold(threshold=0.01)),\n",
       "                ('scale', StandardScaler()),\n",
       "                ('lr',\n",
       "                 LogisticRegression(class_weight='balanced', random_state=0))])"
      ]
     },
     "execution_count": 1643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold # Відкинути ознакиб, які мають нульову дисперсію (або власний поріг)\n",
    "\n",
    "pipeline = Pipeline([('feature_selection',VarianceThreshold(threshold=0.01)),\n",
    "                    ('scale', StandardScaler()),\n",
    "                    ('lr', LogisticRegression(class_weight='balanced' ,random_state=0))]).fit(X_train, Y_train)\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RI', 'Fe'], dtype='object')"
      ]
     },
     "execution_count": 1644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns[~pipeline.named_steps['feature_selection'].get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1645,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forth Model: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        49\n",
      "           1       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.96        54\n",
      "   macro avg       0.86      0.98      0.91        54\n",
      "weighted avg       0.97      0.96      0.97        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Forth Model: \\n\", classification_report(Y_test, pipeline.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1646,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA # Видобуває ознаки з максимальною дисперсією\n",
    "\n",
    "pipeline = Pipeline([('normalize', MinMaxScaler()),\n",
    "                    ('pca', PCA(4, random_state=0)),\n",
    "                    ('lr', LogisticRegression(class_weight='balanced', random_state=0))]).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fifth Model: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        49\n",
      "           1       0.56      1.00      0.71         5\n",
      "\n",
      "    accuracy                           0.93        54\n",
      "   macro avg       0.78      0.96      0.84        54\n",
      "weighted avg       0.96      0.93      0.93        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Fifth Model: \\n\", classification_report(Y_test, pipeline.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1648,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion # Для одночасного використання декількох функцій для покращення або ж попередньої обробки\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe'], dtype='object')"
      ]
     },
     "execution_count": 1649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# For both Classification and Importance checking. Don't need Scaling At All\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=0).fit(X_train, Y_train)\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00576163, 0.        , 0.        , 0.        , 0.13675516,\n",
       "       0.09083583, 0.        , 0.76664738, 0.        ])"
      ]
     },
     "execution_count": 1650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.feature_importances_\n",
    "\n",
    "# Last Time we wanna Omitt RI and RE - [0] and [9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1651,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model = DecisionTreeClassifier(class_weight='balanced',random_state=0).fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sixth Model: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        49\n",
      "           1       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.96        54\n",
      "   macro avg       0.86      0.98      0.91        54\n",
      "weighted avg       0.97      0.96      0.97        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sixth Model: \\n\", classification_report(Y_test, decision_tree_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1653,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # Опорні Вектори\n",
    "# SVM, як правило, стійкі до викидів і можуть моделювати нелінійні межі рішень\n",
    "\n",
    "svc = SVC(gamma='auto', class_weight='balanced').fit(X_train, Y_train)\n",
    "svm_preds = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1654,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seventh Model: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Seventh Model: \\n\", classification_report(Y_test, svm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge : 0.7999461590288737\n",
      "Lasso : -0.039224489795918416\n",
      "ElasticNet : -0.039224489795918416\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "ridge, lasso, elastic = Ridge(), Lasso(), ElasticNet()\n",
    "\n",
    "\n",
    "for model in [ridge, lasso, elastic]:\n",
    "    model.fit(X_train, Y_train)\n",
    "    print(model.__class__.__name__, \":\", model.score(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
